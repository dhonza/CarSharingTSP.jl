{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "using BSON: @load, @save\n",
    "using JSON\n",
    "using DataStructures: DefaultOrderedDict, OrderedDict\n",
    "using Flux\n",
    "using NPZ\n",
    "using FluxGoodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"../exp/full/8/group_data_size/1024_512_256\";\n",
    "transform_json = \"../data/full/8/group_data_size.transform.json\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model from BSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(Chain(Dense(51, 1024, relu), Dense(1024, 512, relu), Dense(512, 256, relu), Dense(256, 1)))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@load joinpath(model_dir, \"model.bson\") cpumodel\n",
    "cpumodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate \"random\" input data (single sample ones) and evaluate the model for it as a sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×1 Array{Float32,2}:\n",
       " 9.700974"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = ones(51,1)\n",
    "cpumodel(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export parameters (weights and biases) of all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "function export_model(model_dir)\n",
    "    @load joinpath(model_dir, \"model.bson\") cpumodel\n",
    "    ps = collect(params(cpumodel))\n",
    "    d = Dict{String,Any}()\n",
    "    nlayers = length(ps) ÷ 2\n",
    "    for i in 1:nlayers\n",
    "        d[\"W$i\"] = ps[2i-1]' # Note Python uses row-first approach to store matrices, so every matrix is transposed\n",
    "        d[\"b$i\"] = ps[2i]'\n",
    "    end\n",
    "    npzwrite(joinpath(model_dir, \"model.npz\"), d)\n",
    "end\n",
    "\n",
    "model = export_model(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each input gets standardized before feeding the MLP, hence we need to extract all $\\mu$ and $\\sigma$ values, too. Let's read them from dataset transformation JSON. We must read them in order, hence the `OrderedDict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "function export_standardization(model_dir, transform_json)\n",
    "    transforms = JSON.parsefile(transform_json, dicttype=OrderedDict)[\"trns\"][\"X\"];\n",
    "    μs = [trn[\"μ\"] for trn in values(transforms) if trn[\"type\"] == \"Standardize\"]\n",
    "    σs = [trn[\"σ\"] for trn in values(transforms) if trn[\"type\"] == \"Standardize\"]\n",
    "    d = Dict(\"mus\" => μs, \"sigmas\" => σs)\n",
    "    npzwrite(joinpath(model_dir, \"model_standardization.npz\"), d)\n",
    "end\n",
    "\n",
    "export_standardization(model_dir, transform_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.1",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
